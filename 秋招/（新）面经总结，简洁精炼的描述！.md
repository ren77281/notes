```toc
```


## 语言

### volatile关键字
先介绍作用：修饰变量，用于告诉编译器，该变量的值可能在程序外部被改变，防止编译器将变量的值优化到缓存或寄存器中，每次都从内存访问变量，以读取最新值。

再介绍场景：
1. 在多线程环境中，修饰共享变量，确保对共享变量的读写操作有效，不会被编译器优化掉。
2. 在信号处理函数中，确保对变量的修改能够被正确的读取。
3. 在嵌入式设备的程序中，硬件设备的寄存器值可能随时发生变量，用volatile修改寄存器值，确保每次访问都获取最新值。

总结：总的来说volatile保证了内存可见性。

### 谈谈malloc的底层实现
malloc用于动态分配指定大小的内存资源。通过brk/mmap系统调用获取内存块，并返回合适内存块的指针，并用链表维护空闲的内存块。

具体来说：malloc会先访问空闲链表，返回合适大小的内存块。如果不存在合适的内存块，将进行系统调用。

brk用于调整调整数据段的结束位置，从而扩展/缩小可用的堆内存。分配的内存连续，常用于小块的内存分配。

mmap映射任意大小的内存区域，适用于大块的内存分配，可以减少内存碎片，但开销大于brk。

系统调用获取的内存资源可能超出实际需求，malloc将多余内存拆分，并加入到空闲链表中。对于每个返回的内存块，都存在一个元数据区域，存储块的大小信息，便于free的内存释放。

此外，malloc会将内存对齐至特定的边界，如8，16字节，以提高缓存命中率，减少内存访问次数。

### 引用和指针的区别
引用是已存在对象的别名，必须初始化且无法更改。指针是存储对象地址的变量，可以为空也可以指向不同对象。

引用不占用额外的内存，不需要解引用操作，访问引用就是访问原对象。

指针常用于实现数据结构（链表，树），以及运行时需要改变指向的场景。

### C++11的新特性
1. 智能指针
2. lambda
3. 右值引用与移动语义
4. tuple容器，存储不同类型的元素
5. 语法糖：范围for，底层是基于迭代器的遍历
6. 关键字：constexpr，用来在编译其计算表达式

### C++的内存管理，和C语言对比
先回答进程的内存区域有哪些：从低地址到高地址分别是：代码区、全局数据区、堆区、共享区、栈区。

再回答C++的new和delete：new和delete作为C++的关键字，分别用来申请和释放堆区的内存资源。如果要申请数组资源，需要在关键字后加上中括号。

最后提一嘴智能指针：从C++11开始，可以使用智能指针：shared_ptr和unique_ptr管理堆区资源，避免内存泄漏。

### 介绍智能指针
先概括要点：unique_ptr和shared_ptr是C++11引入的智能指针，利用RAII来自动管理堆区资源。具体的说，创建对象时，申请资源。当对象的生命周期结束时，释放资源。

再分别细说：

unique_ptr独占资源所有权，不可拷贝，只能被移动。通常用于确保一个对象只有一个所有者的场景。

shared_ptr共享资源所有权，多个shared_ptr可以指向同一个对象。使用引用计数跟踪对象的生命周期，当最后一个shared_ptr的生命周期结束时，资源才会被释放。

但是shared_ptr会造成循环引用问题。

### shared_ptr的循环引用问题
描述问题：当两个对象互相持有指向对方的shared_ptr，并且这两个对象的资源由shared_ptr管理。将导致引用计数无法清零，对象的析构函数永远不会被调用，内存无法释放。

解决方法：使用weak_ptr代替任意一个shared_ptr，weak_ptr不会增加引用计数，从而打破循环。

### C++四种类型转换
- static_cast：用于基本类型之间的类型转换，不进行运行时的类型检查
- dynamic_cast：用于继承体系中父子指针的类型转换，在运行时进行类型检查，失败返回nullptr
- const_cast：用于添加或去除变量的const属性
- reinterpret_cast：用于不同类型之间的转换，不进行运行时的类型检查，和C语言的类型转换相同，重新解释一个变量，这是一个危险的类型转换

### 什么是多态
多态是面向对象编程中的一个重要特性，不同对象对同一接口表现出不同行为。

主要分为静态多态与动态多态：静态多态通过函数重载与运算符重载实现，在编译时确定函数调用。动态多态通过虚函数实现，父类的指针或者引用调用虚函数时，根据对象的类型调用相应的方法，在运行时确定函数调用。

### 谈谈虚函数
先简要概述：虚函数是实现运行时多态的一个机制。子类重写父类的虚函数，在运行时根据对象的类型选择合适的函数调用。

再展开说明：用virtual修饰的成员函数就是虚函数。通过父类指针或引用调用虚函数时，程序会根据对象的虚函数表决定需要调用的函数，这种行为叫做动态绑定。具体来说，子类向父类继承虚函数表，虚函数表指向了函数所在的地址。如果子类重写父类的虚函数时，将用新的函数地址覆盖原函数地址，所以重写也称为覆盖。

最后说明虚函数的开销：但是虚函数表的维护以及通过表查找函数将带来额外的运行时开销。

总之，虚函数使程序更加灵活，但带来了额外的开销。

### 为什么有些类的析构函数设计成虚函数？
确保父类指针或引用在删除子类对象时，能够正确调用子类的析构函数，防止子类部分的资源泄漏。

### 虚函数表存储在哪？
编译器会为每个具有虚函数的类生成一张虚函数表，程序在加载类时将生成虚函数表并存储在全局数据区。每个包含虚函数的对象有一个隐藏的虚指针，指向了全局数据区的虚函数表，虚指针存储在栈区/堆区。

### 虚函数可以被声明为内联吗？
不能。内联需要在编译期间确定函数调用，并展开函数。而虚函数的函数调用在运行时确定。因此，编译器无法展开一个虚函数。
### TODO
### 虚函数表属于类还是对象
虚函数表（vtable）属于类而不是对象。每个包含虚函数的类在内存中只会有一个虚函数表，表中存储指向虚函数的指针。对象在创建时会包含一个指针（虚指针，vptr）指向该虚函数表，因此不同对象共享同一个类的虚函数表。这使得多态性得以实现。
### brk与mmap的区别？

### 谈谈你对封装的理解？
封装是面向对象编程中的核心概念，指将对象的属性和行为隐藏在类的内部，只通过公共接口与外部交互。这样可以保护对象的内部状态，防止外部直接修改，增强代码的可维护性和安全性。封装提高了模块化，降低了系统的耦合度，使得对象的实现细节对外部透明，只暴露必要的接口。
### 移动是什么？
移动也称掠夺，是指将资源从源对象转移到目标对象上，并使源对象进入空状态，无需进行深拷贝。移动操作通常通过移动构造函数和移动赋值运算符实现，使用`std::move`将对象转换为右值引用，从而避免不必要的拷贝，提升性能。
### new和malloc之间的联系？
`new`和`malloc`都用于动态内存分配，但它们的区别在于：
1. 内存分配：`malloc`只分配内存，不调用构造函数；`new`不仅分配内存，还会调用对象的构造函数。
2. 释放内存：`free`释放`malloc`分配的内存，但不调用析构函数；`delete`释放`new`分配的内存，并调用对象的析构函数。
3. 类型安全：`new`返回对象的正确类型指针，`malloc`返回`void*`，需要显式转换。
4. 底层联系：new实际上是对malloc的封装，底层复用了malloc，可以将new理解为malloc的适配器。
两者联系在于，它们都负责分配堆内存，但`new`更适合C++对象，`malloc`主要用于C语言或不涉及对象构造的场景。
### C和C++区别
1. 面向过程 vs 面向对象：C是面向过程的编程语言，C++支持面向对象编程，引入了类、继承、多态等特性。
2. 函数和数据：C强调函数对数据的操作，C++引入封装，通过类将数据和操作封装在一起。
3. 内存管理：C使用`malloc/free`进行手动内存管理，C++提供了`new/delete`，并支持智能指针自动管理内存。
4. 标准库：C++有更丰富的标准库，如STL（标准模板库），提供容器、算法等高级功能。
5. 类型检查：C++有更严格的类型检查，支持函数重载、运算符重载等特性，而C没有这些特性。
总体来说，C++是C的扩展，兼容C的大部分语法，但提供了更多的编程抽象和工具。

### 讲一下深拷贝浅拷贝，如何实现深拷贝
浅拷贝复制对象时，只复制指向资源的指针，两个对象共享同一份资源。修改资源会影响所有共享的对象。
深拷贝则复制对象时，不仅复制指针，还复制资源本身，两个对象拥有独立的资源，互不干扰。
实现深拷贝：在拷贝构造函数或赋值运算符中，动态分配新内存，并复制原对象中的资源内容。

### 讲一下内存对齐
内存对齐是指在访问内存时，将数据按照特定的边界（如2字节、4字节、8字节）对齐，以提高CPU的访问效率。未对齐的数据可能导致额外的内存读写操作，影响性能，甚至在某些架构下引发错误。

编译器通常会自动进行内存对齐，通过插入填充字节（padding）保证结构体成员按适当的地址对齐。开发者可以使用`#pragma pack`或`alignas`等指令调整对齐方式，但需要权衡性能和空间。
### 内存对齐的规则
### 现在有一个shared_ptr，调用函数传递它再返回，会发生什么，说一下这个过程
- **传递时**：`shared_ptr`的引用计数增加，因为传递的是一个拷贝。多个`shared_ptr`实例共享同一资源。
- **函数内部**：函数内部的`shared_ptr`和外部的`shared_ptr`共享同一资源，引用计数持续有效。
- **返回时**：返回的`shared_ptr`再次增加引用计数。
- **函数结束**：函数内部的局部`shared_ptr`销毁，引用计数减少。但返回值的`shared_ptr`仍然保持资源有效。
### 构造函数能否定义为虚函数
程序需要根据对象的虚函数表来确定需要调用的函数，而构造函数执行时对象尚未完全构造，因此程序无法确定需要调用的函数。
### 谈谈左值与右值
左右值作为值类别，用来描述表达式的类型。
左值表示持久对象，占用着持久的存储空间，可以获取其地址，例如变量，数组中的元素。可以位于赋值操作符的左侧，也可以位于右侧。
右值表示临时对象或字面值，不占据持久的存储空间，不可获取其地址，因为生命周期短。例如字面常量，临时对象，表达式的结果。只能位于赋值运算符的右侧。右值可以通过右值引用绑定，允许对临时对象进行修改与优化。

区别则从存储属性，生命周期，是否能取地址三个方面展开。

最后提一嘴右值引用：C++11引入右值引用，目的是为了优化临时对象的传递与资源管理，主要用于实现移动语义和完美转发，实现资源的转移，提高程序效率，避免不必要的拷贝操作。
### 谈谈完美转发
完美转发是C++模板编程中的一种技术，用于在函数模板中将参数“按原样”传递给另一个函数，确保参数的左右值属性不变。它通过万能引用（T&&）和std::forward实现，允许模板函数既能接受左值又能接受右值，并将其正确地转发给目标函数，防止右值被错误地传递为左值，进而导致多余的拷贝操作影响程序的性能。
### std::move和std::forward的区别
主要区别在于它们的用途和行为：
- std::move：用于实现移动语义，无条件地将对象转换为右值引用，表示该对象的资源可以被移动而不是被复制。具体来说，它不会真正移动对象的资源，只是将对象转换成右值引用类型。
- std::forward：用于完美转发，能够根据对象的实际类型保持其左右值属性，再将其传递，确保程序执行正确的拷贝行为。一般结合万能引用使用
### vector可以存储引用吗？
引用是已存在对象的别名，不能为空，不能改变指向。而vector有一个resize功能，可以扩容数组，并用存储类型的默认值填充数组。而引用没有默认值，它必须指向一个对象，因此vector不可以存储引用。
## STL/数据结构与算法相关
### STL常见容器的实现与特点
vector：动态数组。使用连续的内存块存储元素，支持快速的随机访问。扩容时会重新分配更大的内存，并复制现有元素。除了尾部元素的插入与删除，其他位置元素的插入与删除都会导致部分元素的移动，效率较低。

list：双向链表。使用非连续的内存块存储元素，不支持随机访问。适合频繁的插入/删除操作。

set/map：基于红黑树实现，保证元素有序，插入/删除/查找的时间复杂度是$O(logN)$

unordered_set/unordered_map：基于哈希表实现，元素无序，插入/删除/查找的平均复杂度是$O(1)$

### STL容器存在哪些迭代器失效的问题？
首先说明迭代器失效指的是：迭代器指向了不同元素或者未知元素，继续访问失效的迭代器是未定义行为，可能导致程序的崩溃。

- vector, deque, string：
  - 插入将导致指向该元素以及后续元素的迭代器失效。如果触发了扩容，将导致所有的迭代器失效。
  - 删除将导致指向该元素以及后续元素的迭代器失效
- list, set, map：
  - 插入元素不会导致任何迭代器失效
  - 删除元素只会导致被删除元素的迭代器失效
- unordered_set, unordered_map：
  - 由于底层是哈希表，插入元素可能导致分裂rehash，使得所有元素的迭代器失效
  - 删除元素只会导致被删除元素的迭代器失效，但可能导致合并rehash使得所有元素的迭代器失效
### TODO
### 红黑树的特点
作为自平衡二叉搜索树，通过为每个节点附加颜色信息来保持树的平衡，确保基本操作的时间复杂度为 O(log n)。红黑树遵循以下五个规则：
1. 节点要么是红色，要么是黑色。
2. 根节点必须是黑色。
3. 每个叶子节点（NIL 节点）都是黑色。（叶子节点指的是指向空节点的指针）
4. 如果一个节点是红色的，则它的两个子节点必须是黑色的。（即不能有连续的红色节点）
5. 从任一节点到其所有后代叶节点的所有路径上，必须具有相同数量的黑色节点。

### 常见排序算法
1. 比较排序
- **冒泡排序**（Bubble Sort）：每次比较相邻元素并交换，时间复杂度为 O(n2)。
- **选择排序**（Selection Sort）：每次选择最小（或最大）元素放到正确位置，时间复杂度为 O(n2)。
- **插入排序**（Insertion Sort）：将元素插入到已排序的部分，时间复杂度为 O(n2)，对于几乎有序的数组效率较高。
- **归并排序**（Merge Sort）：分治法，将数组分为两部分分别排序并合并，时间复杂度为 O(nlog⁡n)。
- **快速排序**（Quick Sort）：分治法，选基准元素，递归排序，时间复杂度平均为 O(nlog⁡n)，最坏情况 O(n2)。
- **堆排序**（Heap Sort）：基于堆的数据结构，时间复杂度为 O(nlog⁡n)。

2. 非比较排序

- **计数排序**（Counting Sort）：适用于元素范围较小的数组，时间复杂度为 O(n+k)，其中 kkk 是最大元素值。
- **桶排序**（Bucket Sort）：将数据分布到多个桶中，再对每个桶进行排序，时间复杂度平均为 O(n+k)。
- **基数排序**（Radix Sort）：按位或按位数进行多次排序，时间复杂度为 O(nk)，其中 k 是元素位数。
## Linux系统
### 常见Linux系统命令
1. 基础文件操作：ls, cd, pwd, mkdir, touch, mv, cp, rm
2. 资源相关：ps, top, df, tar
3. 查看相关：find, grep
4. 传输文件：scp

### 可执行程序如何产生？
从编译+链接两个方面去回答，分为四个方面：
1. 编译：编译器将源程序翻译成目标代码，通常生成.o文件
2. 链接：链接器将目标文件和依赖的库文件组合在一起，解决符号引用，生成最终的可执行文件
3. 加载：操作系统将可执行文件加载到内存，并为其分配必要的资源
4. 执行：CPU开始执行内存中的指令，程序正式运行

### 对操作系统的理解
操作系统在应用和硬件之间提供抽象和管理，确保系统能高效运行。主要职责有：
1. 资源管理：分配管理CPU、内存、磁盘等资源
2. 进程管理：调度进程的资源，多进程的并发
3. 内存管理：通过虚拟内存机制，为应用分配内存资源
4. 文件系统：管理文件的存储与访问
5. 设备驱动：控制硬件设备，提供统一接口

### 进程和线程的特点
进程：
- 资源分配的基本单位，拥有独立的内存空间
- 进程间隔离，通信开销大
- 切换开销大，需要保存许多的上下文信息
线程：
- 进程内的执行单元，任务调度的基本单位
- 同一进程下的线程共享进程资源，通信开销大
- 切换成本低

最后总结：线程是轻量级进程，多个线程可以并发执行，提高程序效率。
### 谈谈多进程与多线程
多进程：
- 每个进程独立运行，资源隔离性强，适合处理CPU密集型任务
- 进程间通信复杂，切换开销大， 系统资源占用多
多线程：
- 线程共享进程内资源，切换开销低，适合I/O密集型任务
- 线程间通信简单，需要同步互斥机制避免资源竞争

### 为什么多进程适合CPU密集型任务？
首先回答CPU密集型任务：CPU密集型任务依赖CPU的算力，持续的计算占用了大量的CPU时间。

再回答多进程的优点：
1. 多进程的资源竞争带来的性能消耗少
2. 可以充分利用多核CPU的性能，实现真正的并行
3. 进程具有隔离性，一个进程的崩溃不会影响其他进程，系统整体的稳定性更高

### 为什么多线程适合I/O密集型任务？
首先I/O操作的时间长，将导致CPU的等待，浪费CPU资源。

1. 利用线程的并发性，让一个线程等待I/O操作，其他线程继续执行，提高整体效率
2. 线程并发时，切换的开销低，能有效利用CPU空闲时间
3. 线程的通信成本低，利用传输I/O结果

### 谈谈读写锁与互斥锁
首先锁是用于多线程同步的一种机制，读写锁与互斥锁的使用场景与性能不同。

1. 互斥锁作为独占锁，所有线程必须依次获取锁。这是绝对的串行化调度，任何时刻都只有一个线程能持有锁，适用于需要完全排他的场景
2. 读写锁分为读锁与写锁，对于读锁：只要没有线程持有写锁，多个线程能同时持有读锁。对于写锁，线程持有写锁时，其他线程无法获取读锁与写锁

再谈性能对比：
- 在读多写少的情况下，读写锁的性能由于互斥锁，因为读操作可以并行
- 在写操作频繁的情况下，读写锁的性能优势不够明显，可以考虑用互斥锁完成简单的同步
### TODO
### 死锁是怎么产生的，怎么避免死锁
死锁是在多个进程互相等待资源释放的情况下发生的，通常四个条件同时满足时会导致死锁：
1. 互斥条件：某些资源只能由一个进程占用，其他进程必须等待。
2. 占有且等待：一个进程持有资源并请求新的资源，而这些资源正被其他进程占用。
3. 不可剥夺：资源一旦分配，不能强制从进程中剥夺，必须由占有进程主动释放。
4. 循环等待：存在一个进程链，其中每个进程都在等待下一个进程所占有的资源。

避免死锁的策略：
1. 资源预分配（避免占有且等待）：在进程开始执行前一次性分配所有需要的资源，避免执行过程中再请求资源。
2. 资源剥夺（打破不可剥夺）：允许操作系统在必要时强制剥夺某些资源，使其他进程得以继续执行。
3. 按序分配资源（打破循环等待）：规定所有进程按相同顺序请求资源，防止形成环路。
4. 死锁检测与恢复：允许死锁发生后检测循环等待，并通过终止某些进程或剥夺资源来恢复。
### 操作系统进程调度策略
- 先来先服务（FCFS）：按进程到达的顺序调度，简单但响应时间较长。
- 短作业优先（SJF）：优先调度执行时间最短的进程，能优化平均等待时间，但难以预测进程长度。
- 优先级调度：根据进程优先级进行调度，优先级高的进程先执行，可能导致低优先级进程饥饿。
- 时间片轮转（RR）：每个进程分配一个时间片，时间片到则切换到下一个进程，适用于多任务系统。
- 多级反馈队列：结合优先级和时间片，动态调整进程优先级以实现更公平的调度。

### 进程/线程间通信有哪些方式
- 管道（Pipe）：单向通信，仅适用于父子进程。
- 命名管道（FIFO）：双向通信，支持无亲缘关系的进程。
- 消息队列：通过消息传递进行通信，支持异步操作。
- 共享内存：多个进程共享同一块内存，通信速度最快。
- 信号量：用于进程同步，防止竞争条件。
- 信号：异步通知进程事件或中断操作。
- 套接字（Socket）：支持本地和网络通信，跨进程、跨网络使用。

### 用什么指令查看CPU占用率
top主要包括CPU、内存、任务、运行时间等信息。默认每隔3秒更新一次，可手动输入命令筛选进程，杀死进程。
### 介绍一下io多路复用
I/O多路复用是一种通过单个线程或进程处理多个I/O流的方法，提高了资源利用率。主要特点包括：
1. 事件驱动：通过监控多个I/O操作的状态，及时响应可读或可写事件。
2. 异步处理：允许应用程序在I/O操作完成之前继续执行其他任务，提高并发能力。
3. 常用模型：
    - select：监视多个文件描述符的状态，使用简单，但存在文件描述符数量限制。
    - poll：类似于`select`，没有数量限制，但性能较差。
    - epoll：针对Linux优化，支持大规模文件描述符，性能更优。
### 常见的原子操作有哪些
原子操作是保证在多线程或并发环境下不被中断的操作，保证了数据一致性与完整性。
- 原子读写：保证读取或写入一个变量的操作不会被其他线程打断
- 原子加减：如`fetch_add`、`fetch_sub`，用于对变量进行加减
- 原子逻辑操作：如`fetch_and`、`fetch_or`，进行按位与、或操作。
- 原子比较交换（CAS）：如`compare_exchange`，用于在满足条件时更新变量，常用于无锁并发编程
- 原子交换：如`exchange()`，直接将变量设置为新值并返回旧值，用于无锁算法中的变量替换
### 管道通信涉及磁盘读写吗？
管道通信不涉及磁盘读写。它是内存中的数据传输机制，通常用于同一系统中的进程间通信，数据直接在内核缓冲区中传递，不经过磁盘。
### epoll的两种触发方式，如何选择
1. 水平触发（LT）：
    - 默认模式，只有在文件描述符的状态变化时，才会通知应用程序
    - 当可读或可写时，应用程序必须处理所有可用数据，之后才能再次接收到通知
2. 边缘触发（ET）：
    - 仅在状态发生变化时通知一次，适用于要求高性能的场景
    - 应用程序需要确保在接收到通知后尽快读取数据，否则可能会错过后续事件
- 如果追求易用性和可靠性，选择水平触发（LT）
- 如果需要高性能，且能处理复杂的事件通知机制，选择边缘触发（ET）
### 进程结束时资源释放的顺序
- 将所有打开的文件描述符关闭
- 进程所占用的内存（包括堆和栈）被释放
- 释放进程使用的共享内存和信号量等同步机制
- 所有子线程被终止并清理
- 删除进程控制块（PCB），清除进程的控制信息

### 进程、线程、协程区别
- **进程**：
    - 是操作系统分配资源的基本单位，每个进程有独立的内存空间。
    - 进程之间相互独立，通信相对复杂（如IPC）。
    - 切换开销大，适用于多任务处理。
- **线程**：
    - 是进程内的执行单位，多个线程共享进程的内存空间。
    - 线程之间的通信相对简单，但共享资源需要同步。
    - 切换开销小，适合并发操作。
- **协程**：
    - 是用户级的轻量级线程，通常在单线程中调度执行
    - 协程之间通过上下文切换实现非抢占式调度，开销更小
    - 适合I/O密集型任务和高并发场景，易于实现异步操作
### 解释什么是阻塞什么是非阻塞？
阻塞：指在执行某个操作时，如果无法立即完成，程序会暂停执行，直到操作完成。例如，阻塞的读操作会等待数据可用再继续执行

非阻塞：指在执行某个操作时，如果无法立即完成，程序不会暂停，而是立即返回错误或状态，允许继续执行其他操作。例如，非阻塞的读操作会立即返回，不会等待数据
### 实现非阻塞的I0有哪些方式，比如Linux下有哪些函数
- 设置文件描述符为非阻塞：通过`fcntl()`将文件描述符设为非阻塞模式，例如：
    `fcntl(fd, F_SETFL, O_NONBLOCK);`
- `select()`：监控多个文件描述符，等待其中任意一个可读、可写或发生异常。
- `poll()`：类似`select()`，但没有文件描述符数量的限制，可以监控多个事件。
- `epoll()`：Linux特有，效率更高，适用于大规模文件描述符监控。
### 线程，进程间的同步问题
无论是进程还是线程，同时访问相同的数据，容易导致数据不一致或冲突。此时需要同步机制来协调进程，线程间的执行顺序。
1. 进程同步：通过信号量和条件变量等机制来协调进程之间的执行顺序
2. 线程同步：通常使用更轻量级的同步原语，如互斥锁、读写锁和信号量。线程同步的开销通常低于进程同步，因为线程共享同一地址空间。
### 谈谈用户态和内核态
用户态和内核态是操作系统中的两种运行模式：
1. 用户态：应用程序运行的模式，受限于访问权限，不能直接操作硬件资源。大多数程序在用户态执行，系统调用可切换到内核态。
2. 内核态：操作系统内核运行的模式，拥有最高权限，可以直接访问硬件和管理系统资源。只有内核代码在内核态运行。
区别：用户态受限，安全性高；内核态权限大，但容易引发系统崩溃。
### 谈谈用户态和内核态的切换过程
- 触发切换：用户态程序通过系统调用或中断请求内核服务。
- 保存用户态上下文：保存CPU寄存器、程序计数器、栈指针等信息。
- 切换到内核栈：切换栈指针到内核栈。
- 特权级别提升：CPU模式从用户态切换到内核态。
- 执行内核代码：通过预定义的中断向量表或系统调用表找到对应的内核函数入口，执行相关操作。
- 恢复用户态上下文：执行完毕后，恢复用户态的寄存器和状态。
- 返回用户态：CPU模式切回用户态，继续执行用户程序。
### 谈谈互斥锁与自旋锁的区别
- 互斥锁：
    - 阻塞式等待，线程获取不到锁时进入阻塞，等待唤醒。
    - 适用于锁持有时间较长的场景，因为阻塞期间不会占用CPU资源。
    - 有上下文切换开销，但节省CPU资源。
- 自旋锁：
    - 忙等待式，线程不断循环检查锁状态。
    - 适用于锁持有时间短的场景。
    - 无上下文切换，但可能浪费CPU资源。
### 进程，线程以及协程的具体上下文信息
进程切换时需要保存整个进程的上下文信息，包括CPU寄存器、程序计数器、堆栈指针、内存映射、文件描述符等

线程切换时，保存线程的CPU寄存器、程序计数器、堆栈指针等，但共享同一进程的内存空间和资源

协程切换时，仅保存协程的局部状态，如程序计数器和堆栈，不涉及内核态资源，切换开销更小
### 不同存储设备的访问时间
### 虚拟内存管理的页面置换算法中，理论上最优的算法是哪个？
理论上最优的页面置换算法是 OPT（Optimal Page Replacement Algorithm）。该算法在每次需要页面置换时，总是选择将来最长时间内不会被访问的页面进行置换。

由于 OPT 算法需要预知未来的页面访问顺序，在实际系统中无法实现，因此它通常用于作为其他页面置换算法（如 LRU、FIFO 等）的性能上限进行比较。
### 简述select，poll，epoll的原理
1. `select`
将所有待监控的文件描述符放入一个固定大小的数组，并传递给内核，内核需要轮询该数组检查每个文件描述符的状态。这个数组有大小的限制，一般是1024，可以通过修改参数调整大小。
每次调用select都需要填充文件描述符数组，性能差。返回结果时，需要用户自行遍历数组，以检测哪个文件描述符发生了事件。
2. `poll`
与select相比，poll 使用链表存储文件描述符，没有了数量限制。但是系统依然需要轮询所有文件描述符。用户也需要自行遍历集合。
 3. `epoll`
epoll 是 Linux 特有的系统调用，它通过内核空间的数据结构保存文件描述符，不需要每次调用时传递整个文件描述符集合。epoll提供模式：水平触发和边缘触发。
epoll没有显式的文件描述符数量限制，能够处理大量的并发连接。
- **性能**：`epoll` 在文件描述符数量较大时性能表现优异，因为它只在有事件发生时返回就绪的文件描述符，避免了像 `select` 和 `poll` 那样对整个集合的遍历。其性能与活动文件描述符数量成比例，而非总数。
- **优点**：支持 `epoll_wait` 持续等待就绪事件，减少用户空间和内核空间的切换次数，提高性能，特别适合处理高并发的网络应用。
总结：
- `select` 和 `poll` 都存在文件描述符数量大时性能下降的问题，因为它们都需要对所有的文件描述符进行遍历。
- `epoll` 则通过内核维护事件表，大大提高了性能，特别是高并发的场景下，`epoll` 优于 `select` 和 `poll`。
- `epoll` 适合大规模并发连接，而 `select` 和 `poll` 适合小规模的连接监控。
### LRUK算法介绍
LRUK是一种缓存替换算法，是对经典LRU算法的改进，考虑了历史上的K次访问记录。平衡了缓存的命中率。其核心思想是根据K距离淘汰页面，K距离表示倒数第K次访问时间与当前时间的差值，K距离越大，页面越有可能被T台。K越大算法越依赖历史访问行为，K越小，越接近传统LRU算法。

LRUK算法解决了传统算法中的局部性问题，更适合处理具有周期性或局部性较强的数据。

更好地处理长尾数据，防止缓存抖动：一些长时间才会被访问一次的数据在LRU中容易倍淘汰，而LRUK通过记录多次历史访问，使得这些长尾数据有更大的可能被保留在缓存中。进而提高缓存命中率与系统性能。
### 如何查看进程的磁盘I/O情况
1. cat/pid/io：将显示通过系统调用读写的字节数（无论数据是否经过磁盘），read/write的调用次数，从存储设备中读写的字节数，由于取消或截断未实际写入磁盘的字节数
2. iotop：需要apt下载。包含了进程的磁盘读写速率，从交换分区的读写速度，进程I/O的等待时间占比。-o只显示有I/O操作的进程，-a显示累计的I/O读写量
### 如何排查进程的阻塞原因？
### frame和page的区别
1. **Page（页面）**：是操作系统在虚拟内存管理中使用的基本单位。它代表了在主存和辅存（如硬盘）之间交换的数据块。每个页面的大小通常是固定的，例如4KB。
2. **Frame（框架）**：是主存中的物理内存块，用来存放页面。当一个页面被加载到内存时，它会被放置在一个空闲的框架中。框架的数量决定了系统可以同时在内存中存放多少页面。

在LRUK算法中，主要通过对页面的使用频率和最近访问情况进行管理，以优化内存中的页面替换策略。K表示在最近使用的页面中，记录访问的次数以帮助决定哪些页面应该被替换。
### 如何比较两个文件是否相同？

## 计算机网络

### 每层名称以及各自协议
自上而下分别是：应用层，传输层，网络层，链路层

- 应用层：为应用程序提供网络接口，支持各种网络应用。协议：HTTP, SSH, SCP, FTP, SMTP, DNS
- 传输层：端到端通信，负责数据的完整性与有序性。协议：TCP, UDP
- 网络层：负责路由与寻址，通过IP地址确定数据包的传输路径。协议：IP, ICMP, ARP, RARP
- 链路层：负责数据帧的发送和转发。协议：以太网，PPP

### TCP与UDP的特点与应用
TCP与UDP作为传输层的两个协议，TCP的特点为：
1. 面向连接：通信前需要三次握手建立连接
2. 可靠传输：通过序列号、重传机制、流量控制与拥塞控制，确保数据包按序且完整到达
3. 数据流：以数据流的形式传输，不保留数据边界
4. 传输开销大：需要维护连接与执行各种控制操作
TCP适用于可靠传输的场景：
- HTTP/HTTPS：网页浏览
- FTP：文件传输
- SMTP：电子邮件传输
- SSH：安全登录

UDP特点：
1. 无连接：通信双方直接发送数据包
2. 不保证可靠性：没有可靠性机制，数据包可能丢失，乱序
3. 数据报格式：每个UDP报文独立，保留数据边界
4. 开销小：没有连接状态和流量控制的开销
UDP适用于对传输速度要求高可靠性要求低的场景，如：
- DNS：域名解析
- 视频/语音：视频会议、IP电话
- 在线游戏：实时交互性强的游戏

### 三握
首先简述三次握手的目的：确保客户端和服务器都有能力发送和接收数据，同时防止过时的重复连接造成混乱。

再简述过程：
1. SYN：客户端发送SYN，请求建立连接，并且同步序列号。此时，客户端进入SYN-SENT状态
2. SYN+ACK：服务器回应SYN+ACK，同意连接并且同步序列号。此时，服务器进入SYN-RECEIVED状态
3. ACK：客户端回应ACK，表示请求已经建立，客户端进入ESTABLISHED状态，服务器接收到客户端的ACK后，也进入相同状态，此时连接建立完成

总之，三次握手是为了建立可靠的连接，并确保双方都能正常通信。

### 四挥
目的：确保双方都已经完成数据传输，并安全地释放资源。

过程：
1. FIN：客户端发送FIN，表示希望单方面的关闭连接，不再发送数据，但是可以接收数据。此时，客户端进入FIN-WAIT-1状态
2. ACK：服务器回应ACK，同意客户端单方面关闭连接，但是仍然有数据需要发送。此时客户端进入FIN-WAIT-2状态，服务器进入CLOSE-WAIT状态
3. FIN：服务器发送完数据后，发送FIN表示服务器也要关闭连接，此时服务器进入LAST-ACK状态
4. ACK：客户端回应ACK，进入TIME-WAIT状态，等待2MSL以确认服务器接收到ACK包。进入CLOSED状态，服务器收到ACK包后也进入CLOSED状态，此时连接关闭完成

总之，四次挥手是为了安全的关闭连接，防止服务器的相关连接资源的泄漏。

### HTTP长连接和短连接的区别
短连接：
- 每次请求都建立独立的TCP连接，效率低
- 适用于请求量少或对实时性要求高的场景

长连接：
- HTTP/1.1默认，多个请求共享同一个TCP连接
- 减少连接建立次数，降低请求延迟，提高传输效率
- 适用于请求频繁的场景

### HTTP1.0、1.1、2.0的区别

HTTP/1.0：
- 每个请求使用独立的TCP连接，响应后立即关闭
- 不支持持久连接，每次请求请求需要重新建立连接，效率低
- 缺乏缓存控制机制
HTTP/1.1：
- 默认支持长连接，允许多个请求共享一个TCP连接
- 改进了缓存控制，通过Cache-Control配置详细的缓存策略
- 支持分块传输解码
HTTP/2.0：
- 采用二进制协议，解析效率高
- 支持多路复用，多个请求在一个连接上并行处理
- 引入流的概念和请求的优先级设置
- 使用头部压缩减少传输的数据量
### TODO
### TCP拥塞控制
TCP 的拥塞控制用来防止网络因过载而发生拥塞。主要的拥塞控制算法包括以下几个阶段：
1. 慢启动:
    - 发送方从小窗口开始（通常为1个MSS），每收到一个ACK就将cwnd的大小就增加1，每一轮cwnd的大小将指数式地加倍，直到达到一个阈值（ssthresh）。
2. 拥塞避免:
    - 当达到阈值后，窗口增长变为线性，美收到一个ACK后，cwnd增加1/cwnd，每轮增加一个MSS
3. 快速重传:
    - 当接收到三个重复的ACK时，发送方立即重传丢失的数据包，而不需要等待超时。
4. 快速恢复:
    - 网络可能出现了波动，首先 ssthresh = cwnd/2，然后 cwnd = ssthresh + 3，进入拥塞避免阶段，而不是回到慢启动。
5. 超时重传：
    - 使用拥塞发生算法，ssthresh = cwnd/2，cwnd = 初始值
这些机制通过动态调整发送速率来减少网络拥塞的可能性，确保网络的高效传输。
### 讲讲A, B, C类地址
- A 类地址：其第一个字节的最高位为 `0`。例如，`1.0.0.0`（二进制为 `00000001`）到 `126.255.255.255` 的范围。支持大规模网络，主机数量多。
- B 类地址：其第一个字节的最高两位为 `10`。例如，`128.0.0.0`（二进制为 `10000000`）到 `191.255.255.255` 的范围。适合中等规模网络。
- C 类地址：其第一个字节的最高三位为 `110`。例如，`192.0.0.0`（二进制为 `11000000`）到 `223.255.255.255` 的范围。适合小规模网络。
## 数据库
### MySQL的层次结构
1. 连接层：处理客户端连接，认证用户，分配线程处理请求
2. 服务层：解析SQL，生成并优化执行计划
3. 存储引擎层：负责数据的存储与读取，MySQL支持许多不同特性的存储引擎
4. 存储层：与底层文件系统交互，处理底层文件的读写操作

### 讲一下MVCC的作用，以及它是如何实现的
先说明MVCC的作用：通过维护数据的多个版本，为每个事务提供数据的快照。事务的读操作不会阻塞其他事务的写操作，反之亦然，提高数据库的并发性能。

再说明实现方式：
1. 每个数据保存多个版本，每个版本带有一个事务ID，表示该版本的创建时间
2. 读操作将根据事务ID，选择合适的版本，确保读取到的是事务开始时的数据状态
3. 写操作将生成新的数据版本，并赋予事务ID，保留数据的旧版本
4. 需要GC定期清理无用版本数据

### 事务是什么？ACID？事务是如何实现的？  
先概述事务：一组操作的集合，这些操作要么全部成功，要么全部失败，保证了数据的一致性与完整性。

ACID是事务的四个性质：
1. 原子性：事务中的操作要么全部成功，要么全部失败
2. 一致性：事务执行前后，数据库的状态一致
3. 隔离性：事务之间互不影响，每个都认为当前只有自己在访问数据库
4. 持久性：事务一旦提交，结果永久保存，即使发生故障也不丢失

以MySQL为例，再说实现：
1. 通过undolog记录事务的修改，在事务失败或回滚时恢复数据，保证原子性
2. 通过约束、触发器与规则保证数据从一个一致状态转移到另一个一致状态
3. 通过锁机制与MVCC保证隔离性
4. 通过redolog记录已提交的事务操作，用来在系统故障时重放，保证持久性

### InnoDB和MyISAM的区别
1. 事务支持：InnoDB支持事务，提供ACID，而MyISAM不支持
2. 并发控制：InnoDB使用行锁和MVCC，并发性能好，而MyISAM使用表锁，并发性能差
3. 索引结构：InnoDB使用聚簇索引，主键和数据一起存储，MyISAM采用非聚簇索引
4. 崩溃恢复：InnoDB使用redolog和undolog进行崩溃恢复，MyISAM仅提供简单的修复机制，恢复能力弱
5. 外键支持：InnoDB支持外键

### MySQL是如何保证事务的
只有InnoDB提供事务，答案见“事务是如何实现的”

### MySQL底层数据结构是什么，有什么优势
先介绍B+树：B+树是一种平衡的多路搜索树，所有数据存储在叶子节点，内部节点只存储索引。叶子节点以双链表的方式连接在一起。

其优势为：
1. 平衡树都具有的稳定性：插入、删除与查询的效率都是$O(logN)$
2. 高效的顺序访问：叶子节点以双链表的方式连接在一起，**顺序遍历**时不用从根节点重新查找，范围查询的性能高效
3. 减少磁盘I/O：内部节点只存储索引，减少了节点大小，使得每次磁盘I/O能加载更多的索引到内存中。且节点存储多个键，使得树的高度较低，从而减少了磁盘I/O次数。例如，高度为4，阶数为1024的B+树，大概能存储1万亿条数据

### 讲一下四种隔离级别
四种隔离级别定义了事务间的程度，由弱到强分别是：
1. 读未提交（Read Uncommitted）：存在脏读问题，事务可以读取到其他事务未提交的修改
2. 读提交（Read Committed）：存在不可重复读问题，事务可以读取到其他事务提交的修改（Oracle以及大多数数据库默认）
3. 可重复读（Repeatable Read）：避免了不可重复问题，存在幻读问题，两次查询相同的范围时，得到的结果不一致（InnoDB默认隔离级别）
4. 可串行化（Serializable）：事务按顺序执行，完全隔离，避免所有并发问题，效率低

### 详细讲一下读已提交
- 避免脏读：只能读取已经提交的数据
- 存在不可重复读问题，多次读取相同的数据可能存在不同的结果

以InnoDB为例，读已提交通过MVCC实现：
- 每次的读取操作都将生成ReadView，记录当前数据库活跃的事务ID
- 通过目标数据行的版本链，找到第一个已提交的版本（事务ID不在ReadView中）并读取

### 详细讲一下可重复读
- 避免脏读，不可重复读，读取同一数据的结果一致
- 存在幻读问题，可以读取到其他事务Insert的数据

以InnoDB为例，可重复读通过MVCC实现：
1. 事务开始时，删除ReadView，记录当前数据库活跃的事务ID
2. 每次的读取操作都将访问同一ReadView，读取已提交的数据版本

### InnoDB如何解决幻读问题？
InnoDB利用间隙锁与临建锁解决幻读。

TODO

### 可串行化是怎么避免的三个事务问题？
可以通过严格二阶段锁确保可串行化的并发控制。
1. 锁的获取阶段：读操作获取共享锁，写操作获取排他锁。事务在执行的过程中，将不断获取锁
2. 锁的释放阶段：事务不得提前释放锁，只能提交，回滚之后，统一释放锁资源
本质就是通过增加锁的粒度保证事务隔离性，但是存在死锁问题，需要后台运行一个死锁检测线程来破坏死锁。

### Redolog怎么保证事务不丢失？
redolog作为预写机制的一部分，记录的数据页的物理修改信息，事务提交的修改需要先写入redolog并持久化到磁盘，再将修改写入内存。系统崩溃重启时，数据库可以通过redolog重做这些修改，保证数据的一致性和完整性

### 一条select语句底层实现是怎样的？
1. 可能会检查查询缓存，如果相同的查询被执行过，直接返回查询结果 
2. Parser：将SQL文本转换成抽象语法树（如果你学过了编译原理，就能很好的理解） 
3. Binder：将抽象语法树中的符号（表名、列名、索引名等）转换程DBMS认识的符号（ID、标识符）。转换的同时会进行检查，判断用户的SQL是否逻辑合法 
4. Planner（Tree Rewrite）：将抽象语法树转换成树状执行计划，作为优化器优化的起点 
5. Optimizer（数据库中最难实现的模块）：对执行计划进行优化，如谓词下推，投影下推，连接顺序调整，全表扫描转点查询 
6. Executors：执行计划树中的每个节点向子节点索取数据，将处理后的数据返回给父节点，执行计划树的根节点将输出最终的执行结果

### Mysql有很大的数据量怎么办？怎么分表分库？
分库分表有两个方向：水平拆分与垂直拆分。

垂直拆分：
1. 表的垂直拆分：将一个表按字段拆分，将常用子段与不常用字段分开存储，减少表的宽度。例如用户表的基本信息与扩展信息
2. 库的垂直拆分：根据业务模块将不同表拆分到不同数据库中，减轻单个数据库的压力。例如将用户、订单、商品表分到不同的数据库中
水平拆分：
1. 表的水平拆分：将表中的数据按一定规则拆分成多个子表，比如ID范围，时间范围或hash取模，这样做能减少表的整体数据量
2. 库的水平拆分：按照表的水平拆分规则，拆分数据库，每个数据库存储部分子表

### inner join如何实现
先介绍inner join的作用：用于连接两个表中，满足连接条件的记录。实现方法有嵌套循环，排序合并与哈希连接。
1. 嵌套循环：遍历外表记录的同时，遍历内表记录，比较连接列是否相等。适用于外表较小且内表有合适的索引的情况
2. 排序合并：分别根据连接条件对两个表进行排序，再用类似归并排序的方法合并两张表。适用于两表较大且连接字段已经排好序的情况
3. 哈希连接：将较小的表按照连接字段生成哈希表，再遍历较大的表，利用哈希表查询匹配的记录。适用于两表较大且连接字段没有索引的情况

### 为什么redis用跳表不用红黑树不用B+树
1. 跳表结构简单，易于实现
2. 性能稳定，插入和删除操作无额外开销。例如B+树的分裂与合并，红黑树的旋转
3. 支持顺序遍历，根据多层索引快速定位范围的起点，并通过底层链表顺序遍历
4. **内存友好**，B+树面向磁盘设计，针对磁盘I/O做了很多地优化，
### 谈谈B+树的写放大行为
1. B+树结构自身的写放大：节点满了，触发分裂操作时，将重新分配节点中的数据，也就是移动部分数据到新节点中。并且分裂的节点还可能上推到父节点或者更高层的节点，导致它们的分裂
2. 磁盘同步：B+树面向磁盘存储数据，更新数据时，将优先更新内存中的数据，再同步数据到磁盘，这个过程叫做刷脏。由于系统与磁盘I/O的基本单位为4KB，如果更新的数据量不是4KB的整数倍，将放大实际的写入量
优化方法：缓存小规模写入操作，达到一定阈值再刷新磁盘
### 为什么数据库复用文件系统的存储模块，却实现缓存模块
数据库复用文件系统是为了简化存储管理，借用操作系统的成熟功能。但文件系统缓存是通用的，不一定符合数据库对性能、事务一致性等高要求。因此数据库实现自己的缓存池，可以更好地控制内存使用、减少磁盘IO、优化查询性能，并提供对事务的一致性保证。

例如：预取机制，缓存淘汰策略，以及刷脏时机的控制。数据库需要根据自身的访问模式进行更细粒度的优化。

### Redis的AOF和RDB介绍
AOF：Redis 将每次写操作以追加方式记录到 AOF 文件中，类似于日志。当 Redis 重启时，将按顺序地重放 AOF 文件中的操作以恢复数据。我们可以手动地配置写入AOF文件的频率，并且AOF文件是纯文本格式，便于理解与修复。但AOF文件较大，需要定期地重写以恢复文件，由于需要重放所有写操作，恢复时速度相对较慢。

RDB：Redis 会在指定的时间间隔内，将内存中的数据快照保存为一个 RDB 文件。当 Redis 重启时，直接从快照文件加载数据。RDB 是二进制快照文件，恢复速度较快，相比 AOF，RDB 文件较小，生成效率更高。但RDB 是定时生成快照，若 Redis 异常宕机，可能丢失最后一次快照后的数据。

总结来说，AOF 保证了数据的完整性，而 RDB 提供了快速的恢复，两者可以根据具体需求选择使用或组合使用。
### 慢SQL优化
- **索引**：确保查询条件使用适当索引，避免全表扫描。
- **查询优化**：减少查询字段，使用`EXPLAIN`分析执行计划，避免复杂查询。
- **表结构**：合理设计表结构，选择合适的数据类型。
- **缓存**：使用缓存减少频繁查询压力。
- **事务与锁**：缩小事务范围，减少锁等待。
- **硬件与配置**：优化数据库配置，提升硬件性能。

为什么Join算法中，外表的page数量较少？
排序算法相关：稳定排序啥的

C++锁的实现
mysql索引的原理，索引失效的场景，和一道索引命中场景题
Redis有什么瓶颈
## 常见计模式
### 介绍一下常见的设计模式
1. 

手撕快排算法
手撕工厂模式代码
手撕线程安全的单例模式
手撕智能指针 



## 其他
### 讲一下gRPC
先大致概括，传输协议与传输格式：gRPC是一个高性能，开源的远程过程调用（RPC）框架，基于HTTP/2协议与Protocol Buffers（protobuf）序列化格式。

再介绍传输方式与使用场景：支持多种编程语言，允许客户端与服务器之间通过定义好的服务接口进行通信，适合分布式系统中的微服务结构。

最后介绍高级特性：gRPC还支持双向流、负载均衡、认证和压缩等高级特性。

### gRPC是如何实现通信的

