```toc
```
**什么是持久化？**
将主机重启之后，数据是否存在？若存在，就是持久，反之则为不持久
显然，将数据存储在内存中，重启主机后，数据将丢失
所以，redis为了防止数据的丢失，需要实现持久化，即存储数据到硬盘中

redis以内存为主，硬盘为辅存储数据，理论上两者存储的数据是相同的，实际上存在小概率的差异
写入数据时，不仅向内存写入，（同时）还向硬盘写入数据。而读取数据时，只从内存中读取以提高响应速度。当redis服务重启时，将硬盘中的数据恢复到内存中

redis的持久化策略：
- RDB：Redis Database（定期备份，redis默认开启）
- AOF：Append Only File（实时备份）
## RDB介绍
RDB定期地将所有数据写入硬盘中，生成一个"快照"（redis将数据的数据拍成照片，存储到硬盘中）

定期备份：
- 手动触发：通过redis客户端，执行save/bgsave触发，生成快照
- 自动触发：修改redis的配置文件，让redis每隔特定的时间就触发

执行save时，redis将阻塞其他命令以执行save，一般不建议使用
bgsave：不会影响redis服务器执行其他请求和命令。一边执行客户端的请求，一边进行备份，这是一个并发的场景，redis使用“多进程”的方式解决并发
![image.png](https://s2.loli.net/2023/11/02/iUanXwcHMuh4kxK.png)
bgsave的执行过程：
1. 父进程查看当前是否有其他进程在运行，若有则直接将其返回
2. fork出子进程，子进程用于完成快照的生成，父进程继续接收客户端的请求并提供服务
3. 子进程执行结束，通知父进程，父进程接收子进程的一些消息后销毁子进程

RDB机制生成的镜像文件后缀为.rdb
在redis.conf文件下，保存了rdb文件的存储路径
![image.png](https://s2.loli.net/2023/11/02/2zpTBIh485UHuwd.png)

rdb文件是一个二进制文件，redis以压缩的方式将原始数据压缩成二进制文件
![image.png](https://s2.loli.net/2023/11/02/jZ7JvWPDRIw3bkE.png)

生成rdb镜像时（完成之前），会将数据保存到一个临时文件中。快照生成完毕之后，会将之前的rdb文件删除（如果有），并修改临时文件为`dump.rdb`，所以无论如何，rdb文件只有一份

执行bgsave前后，通过stat命令查看dump.rdb文件的inode，发现inode发生了变化，说明bgsave会生成临时文件并替换原有dump.rdb文件
![image.png](https://s2.loli.net/2023/11/02/CvUleJicb1Q2oKw.png)

![image.png](https://s2.loli.net/2023/11/02/bfa3ryD1YxteTcj.png)

（而执行save就不会创建子进程生成快照，而是直接用当前进程生成快照，且直接向`dump.rdb`写入，并不会创建临时文件）

RDB是定期备份的，在redis.conf配置文件中，相关的信息是怎么写的？
![image.png](https://s2.loli.net/2023/11/02/DUm7c1Ll2FipT4V.png)

当redis达到一定条件时，将触发备份操作，如`svae 900 1`表示900秒中，修改了一次，那么将进行备份。可以修改具体的触发条件，但注意：触发不应该太频繁
若设置`save ""`，将关闭自动备份

在redis客户端中手动执行备份操作：
```cpp
bgsave
```

RDB自动备份的三种情况：
1. 在M秒内修改N次（redis.conf配置文件）触发
2. 通过shutdown命令关闭redis服务器，也会触发（service redis-server restart执行了shutdown命令）。正常关闭会触发备份，但异常操作（kill -9）不会触发
3. redis进行主从复制时，主节点将生成rdb快照，然后将rdb快照的内容传输给从节点

若rdb文件损坏，可能导致redis服务启动失败。redis官方提供了rdb文件的检查工具，该工具在`/usr/bin`路径下
![image.png](https://s2.loli.net/2023/11/02/8IH9WTfcJCkjhsM.png)

同时也能看到redis-server是redis-check-rdb的一个软链接，启动redis-server时添加一些参数就能检查rdb文件了

检查dump.rdb文件是否完整：
```bash
redis-check-rdb dump.rdb
```

删除dump.rdb文件的一些字符后，进行检查：
![image.png](https://s2.loli.net/2023/11/02/vXC1sRmLwPpfVrt.png)

### RDB特点
- RDB是一个紧凑压缩的二进制文件，适用于备份，**全量复制**的场景
- RDB无法做到实时持久化，因为bgsave每次运行都要fork子进程，属于重量级操作，执行成本过高
- redis的演进过程中有多个RDB版本，新版本的redis无法使用旧版本的rdb文件
- RDB的加载速度远远快于AOF，因为AOF使用文本的方式组织数据，需要进行字符串相关操作

## AOF介绍
>AOF**实时保存**

AOF类似于MySQL的binlog，存储了用户的操作命令
redis重启时，将读取AOF文件中的内容，执行操作指令以恢复数据
若开启AOF，那么redis将忽略RDB，启动时不再读取RDB文件内容
AOF默认为关闭状态，需要修改配置文件开启AOF功能
![image.png](https://s2.loli.net/2023/11/02/l18xJ92I63cwnDj.png)
将appendonly改成yes，下面的appendfilename为生成的aof文件名
重新启动redis
```bash
service redis-server restart 
```
此时在`/var/lib/redis`目录下存在aof文件
![image.png](https://s2.loli.net/2023/11/02/RTi1WDv2yzEot5l.png)

aof以文本的方式存储命令，命令之间用特殊分隔符分割
![image.png](https://s2.loli.net/2023/11/02/54loCaQcmisX3zU.png)

### AOF对性能的影响？
使用了AOF，用户每次的操作不仅会修改内存，还会修改硬盘（写入aof文件），所以AOF会影响redis的性能吗？
![image.png](https://s2.loli.net/2023/11/02/ivA54epYtU8yZBf.png)

为了防止频繁的写入硬盘，redis引入了AOF缓冲区，将用户的命令先保存到缓冲区中，当缓冲区满足刷新条件时，再将数据同一写入硬盘
（写入硬盘的次数比起写入数据的多少更影响性能）
AOF为顺序写入，比起随机写入速度更快
### AOF缓冲区的刷新策略
用于AOF先将数据写入内存中的缓冲区，再写入硬盘，若此时服务器断电/崩溃，这些数据依然会丢失
redis给出了选项，让我们配置缓冲区的刷新策略，也就是缓冲区的刷新频率（频率越高越影响性能）
- always：每写入一条数据就刷新，频率最高，效率最低
- everysec：每秒刷新一次，中庸的选项
- no：由OS负责缓存区的刷新，频率最低，效率最高

配置文件中，默认选项为everysec
![image.png](https://s2.loli.net/2023/11/02/ePd9ZVvQDonyLcl.png)

### AOF重写机制
aof文件越来越大，redis的**启动时间**将越来越长
AOF存在重写机制，将剔除aof文件中的冗余操作，或者进行操作合并，达到文件瘦身的效果
也就是说，aof只关注数据库的最终结果，只保存对最终结果有影响的命令

- 手动触发重写机制：bgrewriteaof命令
- 自动触发重写机制：修改配置文件
  - auto-aof-rewrite-min-size：（阈值）超过这个值将触发重写，默认为64MB
  - auto-aof-rewrite-percentage：当前aof占用大小相比于上次的增加比例

![image.png](https://s2.loli.net/2023/11/02/wrP1B3F7URtVXdg.png)

bgrewriteaof重写过程：父进程创建子进程，自己仍然接收用户的请求并处理请求。子进程读取**内存中的数据**（注意：不会读取原aof文件，因为AOF只关注最终的数据），以AOF的格式将数据写入aof文件中
AOF子进程重写的过程，和RDB子进程重写类似。两者的区别在于：RDB以二进制的方式生成文件，而AOF以指定的文本格式生成文件

子进程生成aof文件时，父进程依然在接收请求并写入aof数据到aof缓冲区，缓冲区将数据刷新到旧aof文件中（子进程都要生成新aof文件了，为什么父进程还要维护旧aof文件？生成新aof文件之前，产生异常情况，可以用旧aof文件恢复数据）
同时父进程在fork子进程之后，也需要将之后aof数据写入到aof_rewrite_buf缓冲区，这个缓冲区专门存储fork之后的aof数据。当子进程生成aof文件完成时，会用信号通知父进程，此时父进程再将aof_rewrite_buf中的数据写入新aof文件中。最后用新aof文件替换旧aof文件

执行bgrewirteaof时，可能的两种情况：
- 当前正在执行aof重写，此时不需要再次重写，直接返回
- 当前正在执行rdb重写，等待rdb重写完成，再执行aof重写

可以发现，AOF对于fork之后到重写完成之前的数据也会进行备份（aof_rewrite_buf缓冲区），而RDB则不会备份这些数据，因为AOF属于实时备份，需要保证数据的可靠性

### 混合持久化
AOF以文本格式将命令追加到aof文件中，使用这样的aof文件恢复redis的数据，资源开销大，速度慢
redis提供了一种混合持久化的方式，依然是以文本格式将数据追加到aof文件中，但触发aof重写时，就会将当前的内存状态以二进制格式写入新aof文件中（类似于RDB的重写）

配置文件中，默认开启了混合模式
![image.png](https://s2.loli.net/2023/11/03/Z2cq74vd3DLJzVO.png)
![image.png](https://s2.loli.net/2023/11/03/ZTKRw6nb1L2JgBO.png)
## redis事务
redis的事务是否具有原子性？这个问题的答案具有争议，较多人认为不具有
以MySQL为例，MySQL中的事务，一旦执行失败，将进行**回滚**。所以事务要么执行成功，要么不执行
而redis的事务具有回滚属性，因此redis只保证事务要么执行，要么不执行，至于执行的结果是否正确，redis无法保证

与MySQL对比：
- 不具有一致性：redis没有约束，没有回滚，事务执行过程中某个操作执行失败，将引起数据不一致问题
- 不具有持久性：redis用内存存储数据，虽然具有AOF和RDB持久化机制，但是事务本事不具有持久化
- 不涉及隔离性：redis作为单线程程序，不可能出现并行的场景，也就不涉及隔离性了

redis事务的主要作用是**打包**。客户端无法同时发送不同的命令，将不同命令分开来发送，存在被其他客户端插队的风险。为了防止其他客户端的插队，使用事务将不同的命令打包成一组命令，只有执行完一组打包好的命令，redis才会执行其他命令

对于每个客户端，服务端都会维护一个队列。客户端开启事务时，命令不会真正执行，而是被插入队列中。当客户端发送`执行事务`的命令时，服务端才会从队列中获取命令并执行，直到队列为空
若开启事务后，执行事务前，redis服务器退出，那么未执行的事务将被队列（因为队列存储在内存中）

开启事务：multi
执行事务：exec
放弃事务：discard

![image.png](https://s2.loli.net/2023/11/03/zd2tMqEofGJOeQZ.png)

watch：在multi和exec之间，set key之后，监控key是否被其他客户端修改了，若key被修改，那么watch将禁止当前客户端对key的修改
用`unwatch`取消对key的监控，注意：watch需要在multi之前
比如，当前客户端监控k1，开启事务并修改k1，此时另一个客户端修改了k1，`set k1 333`
当前客户端`exec`执行事务，发现执行失败，原因是k1的值在**set之后，exec之前被修改了**

![image.png](https://s2.loli.net/2023/11/03/3aSmZFfQJg286qd.png)

watch基于版本号的机制，实现了乐观锁
执行watch key时，redis会给这个key安排一个版本号，每次的修改版本号都会变大
exec执行事务时，会读取key的版本号，判断版本号和之前记录的是否相同
若不同，说明set之后exec之前，key被其他客户端修改过，此时放弃修改返回nil
若相同，说明set之后exec之前，key没有被其他客户端修改过，此时进行修改

注意：使用redis的主从复制时，无法使用事务
## 主从复制
redis常用于分布式系统，而引入分布式系统是为了解决一个核心问题：单点
什么是单点？服务器程序只有一个节点（只使用一台服务器来部署服务）
单点可能导致的问题：
1. 可用性，若服务器挂了，就意味着服务直接中断
2. 一台服务器的性能/支持的并发量优先

分布式系统中，常常使用多个服务器来部署redis服务，从而构成一个redis集群，提供更稳定、高效的服务
redis集群的部署方式主要有以下几种：
1. 主从模式
2. 主从+哨兵模式
3. 集群模式

主从模式：在多个部署了redis服务的节点中，选择其中一个作为主节点，其他节点为从节点。从节点必须听主节点的
所以，不允许修改从节点的数据，只能修改主节点的数据。当主节点的数据发生变化，主节点就要将数据拷贝到从节点中，以保证数据一致

主从复制的优点：
1. 用于主从节点的数据一致性，所以无论从哪个节点中读取，得到的数据都是一样的，所以主从复制能够应对读操作的高并发
2. 如果从节点挂了，对整个集群没啥影响。如果主节点挂了，客户端就无法写入向服务端写入数据

如何配置主从模式？
复制主节点的配置文件，修改文件名并编辑该文件，将daemonize设置为yes，表示开启redis后台运行
![image.png](https://s2.loli.net/2023/11/03/agBPzX4ObD8uls2.png)
同时添加slaveof IP port字段，表示该从节点属于那台主节点（用IP和端口唯一表示redis-server进程）
![image.png](https://s2.loli.net/2023/11/03/9muSUAtfKspDP5a.png)
由于我只有一台服务器，所以主节点的IP为环回地址（同时我也需要修改从节点使用的端口，不能和主节点冲突）

输入命令启动redis服务
```bash
redis-server xxx.conf（redis的配置文件）
```
输入命令连接redis服务
```bash
redis-cli -p 端口号
```
注意：通过`redis-server`方式启动的服务，只能使用kill -9停止服务
而使用service redis-server start启动的服务，只能使用service redis-server stop停止服务
因为`service redis-server start`会启动一个守护进程，检测redis-server的运行状态，若运行停止了，将直接重启redis-server，所以此时使用kill -9无法杀死redis-server，因为它拥有守护进程

并且通过`redis-server`方式启动的服务，redis将创建一个名为redis的普通用户以启动程序，目的是为了限制权限
而通过`redis-server xxx.conf`启动的夫婿，redis将以root用户的身份启动

输入命令，查看主从节点信息
```bash
info replication
```
![image.png](https://s2.loli.net/2023/11/03/TRZl29XrhuPGgAn.png)
其中
offset：主从节点之间需要数据同步，offset表示数据同步的位置，通过master_repl_offset可以得知数据同步是否完成
lag：主从节点之间的网络延迟

直接在redis客户端中输入：
```bash
slaveof no one
```
断开现有的主从关系
从节点放弃主从关系时，存储的数据不会丢弃，并且从节点将变成主节点
若不修改节点的配置文件，那么重启服务后，通过命令行修改的主从结构将被撤销

redis默认从节点只读，若允许从节点向数据库的写入，那么主节点无法感知从节点写入的数据，同时也将造成数据不一致的问题，所以不推荐关闭只读

主从节点通过TCP来传输数据
TCP内部支持了nagle算法（默认开启）
开启将增加tcp的传输延迟，但能节省网络带宽
关闭将降低tcp的传输延迟，但增加了网络带宽

在redis的配置文件中，添加`repl-disable-tcp-nodealy`选项将关闭tcp的nagle算法
### 主从模式的拓扑结构
扁平化结构：
多个从节点直接从属于主节点，此时主节点的数据发生变化，就需要将数据同步给多个从节点，从节点的数量越多，同样的数据就要同步多次，对网络带宽的消耗就越大
如果写请求过多，可以关闭主节点的AOF，只开启从节点的AOF
若主节点挂了，就需要从从节点拉取aof文件以启动数据库。若主节点用本地aof文件恢复数据库，将造成严重的数据丢失

树形结构：
主节点作为根节点，只有一部分从节点直接从属于主节点。主节点的数据同步压力由从节点进行分摊
这样的结构虽然分摊了主节点的压力，但是提高了延迟。从主节点到根节点的数据同步将花费更多的时间

### 主从同步
主从同步的过程：
1. 从节点先保存主节点的IP和端口
2. 主从建立TCP连接
3. 从节点发送ping命令，检测主节点是否能够正常工作
4. 权限验证（若redis设置了密码，从节点需要进行密码的验证）
5. 同步数据集（全量同步）
6. 命令持续复制（增量同步）

redis提供了psync命令以完成数据同步的过程，但psync不需要手动执行。建立好主从关系后，从节点将自动执行psync指令
```
psync replicationid offset
```
表示从replid（主节点的id）的offset偏移量开始及进行数据同步

其中涉及到一个重要的属性replid，主节点启动时会自动生成replid，从节点成为主节点时，也会生成replid。即使是同一个主节点，每次生成的replid都是不同的
从节点和主节点建立复制关系，就需要从主节点中获取repid
![image.png](https://s2.loli.net/2023/11/03/KHYWJsymujGrvBI.png)

一般情况下，replid2是用不到的
什么时候会用到？到主从节点的连接出现了网络抖动，从节点可能认为主节点挂了，于是自己成为了主节点，并生成新replid，而旧的replid保存在replid2中
当网络稳定时，从节点可以根据这个replid2与主节点重新建立主从关系（这个过程一般需要手动完成）

另外一个重要的概念：偏移量
主节点将**修改**命令的字节数进行累加，结果就是主节点的offset
而从节点的offset描述了和主节点的同步进度
从节点会定时上报自身的偏移量给主节点，从主节点中获取数据

replid和offset共同描述了一个数据集合，若两个节点的replid和offset都一样，此时可以认为这两个节点存储的数据都一样

psync的执行过程：
1. 从节点发送`psync replicationid offset`给主节点
若offset为-1，表示请求获取全量数据
若offset为具体的数值，表示请求获取增量数据
2. 主节点根据命令返回数据，若从节点请求获取全量数据，那主节点就返回全量数据。若从节点请求返回增量数据，那么主节点视情况返回全量/增量数据。若主节点的redis为老版本，可能会返回err，因为老版本不支持psync，此时使用sync即可

何时进行全量复制：1. 主节点不方便发送增量数据时 2. 从节点首次和主节点同步
何时进行增量复制：1. 从节点已经进行过全量复制，或者因为网络抖动重启，需要重新从主节点获取数据，此时从节点将请求获取增量数据

![image.png](https://s2.loli.net/2023/11/03/5KWp1ITYH6JC3nm.png)

1. 从节点向主节点发送psync进行数据同步，由于是全量复制，所以发送`psync ? -1`
2. 主节点根据命令解析出从节点需要全量复制，所以返回FULLRESYNC响应
3. 从节点接收响应并保存主节点的信息（如replid）
4. 主节点执行bgsave生成RDB文件（由于RDB是定期保存的，为保证数据一致性，不能使用已有rdb文件，必须重新生成。且rdb文件为二进制存储，体积较小），同时将生成RDB文件过程中接收到的命令写入缓存区中（有点像AOF的重写）
5. 主节点发送RDB文件给从节点，从节点保存RDB文件到硬盘
6. 当从节点保存了RDB文件，主节点再将缓冲区中的数据发送给从节点，这些数据以二进制的方式追加到原有RDB文件中
7. 从节点加载RDB文件得到与主节点相同的数据
8. 若从节点开启了AOF，将执行bgrewrite操作，生成aof文件。否则全量复制结束

全量复制时，redis支持无硬盘模式（diskless）
主节点生成rdb文件用来发送给从节点进行数据同步，这个rdb文件可以直接进行网络传输，而不保存到硬盘中。这样就剩下了一系列读取和写入硬盘的操作
而从节点接收到rdb数据时，也可以直接进行加载，不将rdb数据写入到磁盘，这样也剩下了一系列读取和写入硬盘的操作

但是全量复制仍然是一个重量的操作，虽然剩下了硬盘的读写，但是网络传输没有办法省下，而网络传输的速度又是比较慢的

replid和runid的区分
runid用来支持**哨兵**
而replid用来支持**主从复制**
执行`info replication`时，将展示replid的信息，拥有主从关系的节点执行该命令都能得到相同的replid
执行`info server`时，将展示runid的信息，每个节点的runid都不相同，实际上同一节点，每次运行时，runid都不相同

部分复制：可以理解为全量复制的优化手段
![image.png](https://s2.loli.net/2023/11/03/Hg58hdVXjLiSpyQ.png)


1. 出现网络抖动时，主从节点的连接可能会断开，断开时间超过repl-timeout，主从节点的主从关系解除
2. 主节点在关系解除期间依然接收并处理命令，但这些命令无法同步给从节点，所以将这些命令写入积压缓存中
3. 当主从节点的网络恢复正常，从节点再次连接上主节点
4. 从节点将之前保存的replid和offset作为psync参数发送给主节点，请求部分复制
5. 主节点接收psync请求，判断replid和自身的replid是否相同，若相同再判断offset进度是否在积压缓冲区中，若在，则进行部分复制，否则进行全量复制
6. 主节点将数据发送给从节点

![image.png](https://s2.loli.net/2023/11/03/PVI9qOjAWsDNu6J.png)
`info replication`的某些字段就描述了积压缓冲区（repl-backlog-buffer）的信息，该缓冲区其实就是一个环形队列，该队列记录了最近修改的数据。由于是环形队列，所以会将旧的数据覆盖，以不断写入新的数据

实时复制：从节点和主节点已经同步好了数据，随着主节点不断接收新数据，主节点就需要将新数据同步给从节点
主从节点之间通过TCP长连接进行实时复制，主节点发送新的修改给从节点，从节点根据这些数据修改内存中的数据
实时复制时，需要通过心跳包机制保证连接的可用状态：比如主节点每隔10s给从节点发送一个ping，从节点需要返回pong
从节点每隔1s就给主节点发送一个特定的请求，汇报当前的数据同步进度（offset）

主从复制的最大问题在于主节点崩溃时，从节点不会自动升级为主节点
升级过程需要人工干预，并且这种干预比较复杂
redis的哨兵机制提供了对挂了的主节点的**自动**更换

主节点挂了，并不等价于主从节点断开连接
主从节点之间的连接断开，存在两种情况：
1. 从节点主动与主节点断开连接，从节点执行slaveof no one，这时从节点升级成为主节点（主动断开连接意味着我们需要修改拓扑结构，所以从节点会主动升级）
2. 主节点崩溃，这时从节点并不会升级为主节点。从节点依然负责集群的读任务，但是无法进行数据的写入。使用redis的哨兵机制可以解决此问题

人工干预不具有及时性且过于繁琐，所以需要使用哨兵
