```toc
```
## 为什么要做这个项目？
之前用C++做的webserver过于简单，没有亮点，无法体现出技术优势。面试时询问了面试官比较认可哪些项目，了解到一些同学用国外公开课的实验作为自己的项目。迷茫的我就去找公开课做了，因为15445的实验是用C++写的，自己对C++比较熟悉，于是选择了上手成本较低的15445。

## 不同存储介质的访问时间
实际上，一级缓存的访问时间为0.5ns，假设其访问时间为0.5s
- 那么访问二级缓存的时间为7s
- 内存100s
- SSD固态硬盘2天
- HDD机械硬盘20周
- 网络10个月

## 实现事务的可串行化的方案有哪些？
三种：两阶段锁(2PL)，基于时间戳的版本控制(TOCC)，结合前两种的MVCC
## 介绍
主要实现了一个基于LRUK淘汰算法的缓存管理器，但需要先实现基于LRUK淘汰算法的缓存替换器以及用来读写磁盘的磁盘调度器。初始化缓存管理器时，将获取一块内存资源，作为缓存池。缓存管理器在获取存在于磁盘的页面，以及刷脏时需要调用磁盘管理器。在访问页面以及缓存满时，需要访问缓存替换器，来最大化缓存资源的利用率。
## P1：为什么数据库需要实现自己的文件系统的缓存模块？但复用了存储模块？

## P1：LRUK算法介绍

## P1：LRUK算法的具体实现
LRUKNode用来描述页面的历史K次访问记录，所在的帧号，以及K距离。具体是用一个长度不超过K的队列来存储每次的访问时间戳，越近的访问时间将越靠近队头。新增访问记录后，如果队列的长度大于K，那么需要pop一条记录保证队列的长度不超过K。如果访问次数小于K，将使用最近一次访问时间作为参考，此时LRUK等同于传统的LRU。

在替换器中，使用了unordered_map保存帧id与LRUKNode的映射关系。LRUKNode有一个bool属性，表示是否能淘汰该页面。我使用一个set保存所有可淘汰的LRUKNode。每次淘汰时，只需要erase begin迭代器指向的页面即可。

其中还有一个细节就是：如果可淘汰页面的K距离更新，不能通过迭代器修改set中的节点，需要先将其从set中删除，再插入更新后的节点。因为set只会在插入时保存平衡。
## P1：磁盘调度器介绍

## P1：缓存管理器介绍
缓存管理器维护了：一个页数组，数组中每个元素都是指向页结构的指针，帧号实际上就是该数组的下标。除此之外还维护了可使用的空闲帧列表，帧数组中页号与帧号的映射关系。

主要通过NewPage和FetchPage来获取资源，NewPage用于获取全新的页资源，而FetchPage用来获取已经存在的页资源，如果页资源在磁盘上，则需要构造读请求，通过磁盘调度器从磁盘中读取数据到页资源上。而得到页资源的同时会pin住相应的页，使页的使用计数器自增，那么缓存池无法驱逐使用计数器不为0的页。需要调用UnpinPage来使计数器自减，否则将造成资源泄漏。

Remove和Evict用来删除页数组中的页资源。区别就是Evict只有在页数组满时调用，才会执行相应操作。

以及FlushPage对应刷脏操作，它会构造写请求，通过磁盘调度器向磁盘写入页数据。
***
## P2：介绍Extendible Hash Table
首先有三个基础组件：Header Page，Directory Page，Bucket Page。哈希表仅有一张Header Page，它将根据hash值的高位，指向不同的Directory Page，而Directory Page将根据hash值的低位指向不同的Bucket Page，Bucket Page则是用来存储实际数据的页结构。

而这个hash不能存储相同的key，为了解决hash冲突，Bucket Page存储的是key-value键值对，而不是value。
***
## P3：SQL语句的执行过程

## P3：执行计划树中的算子如何获取数据？
每个算子都继承自基类：AbstractExecutor，其拥有一个ExecutorContext成员，该成员包含数据库的所有信息，比如其Catalog成员包含了所有表的信息，Transaction成员包含执行该SQL语句的事务的信息...
物理执行计划树中的每个算子和逻辑执行计划树中的每个节点一一对应。逻辑执行计划树中的节点用PlanNode表示，其包含了SQL语句的表名，谓词表达式等信息。

综上所述，算子通过PlanNode获取SQL语句的信息，再通过ExecutorContext数据库的相关信息。
## P3：BusTub如何存储表的数据？
AbstractExecutor的ExecutorContext成员有一个GetTable()函数，它将返回TableInfo，其包含了表的元信息，如：表的结构Schema，名字，表id，以及最重要的TableHeap。TableHeap用来存储一张表中的所有数据，它是无序的数据页的集合。

具体来说，TableHeap是一张链表，每个节点用TablePage描述。TableHeap中有两个字段：first_page_id，last_page_id，分别指向了链表中的头尾两张TablePage。而TablePage的资源实际上是通过P1实现的缓存池获取的，每个TablePage的有效资源为4KB。

除此之外，TablePage拥有用来唯一标识页的page_id，以及指向下一张page的next_page_id。

综上所述，BusTub使用TableHeap作为链表结构存储数据，而链表中的节点使用TablePage表示。
### TablePage的存储格式
每张page最开始的空间用来存储head，描述了这张page的元数据，记录的数量，删除的记录数量，以及一个槽数组。而槽数组的每个元素描述了记录的位置信息（偏移量+大小）。而每条记录将从page的最后开始，往前存储。也就是从两边到中间使用TablePage的资源。

## P3：聊聊火山模型
火山模型作为一个应用广泛的数据处理模型，几乎所有的DBMS都实现了火山模型，在火山模型中，SQL语句的执行过程像岩浆一样。数据从执行计划树的叶子节点开始往上汇聚，最终在根节点喷发，根节点返回的数据就是整个SQL语句的执行结果。但是我们能轻易地控制喷发的量。比如我们只需要输出100条数据，我们只需要限制上层算子，当其输出到100条数据时，就停止运算。

具体来说：
- 每个算子都向上层提供了Next函数，每次调用Next函数时，算子都会向上层返回记录或者是用来表示后续没有数据的空值
- 每个算子都会不断地调用子节点的Next函数，从而获取需要处理的记录

火山模型也叫流式模型，但Join, Subqueries, Oreder By算子都会阻塞数据的流动

存在的问题：函数调用次数过多，虽然和I/O相比，调用函数的额外开销可以忽略不记，但是相较其他模型，不断调用Next函数导致了极大的开销

其他模型：在物化模型中，节点将一次性处理好所有的数据再返回给父节点。因此数据的流动是经常阻塞的
- 函数调用次数少
- 适合TP场景，因为每个节点需要处理的数据量小

而向量模型作为一个中间派，每次吐出的数据量可变，不再是一条数据或是所有数据。可以充分地利用支持向量指令的CPU的性能
## P3：dynamic_cast在15445中的使用
在实现基于规则的执行计划优化时，用到了dynamic_cast来判断对象的类型。具体来说，执行计划会包含一些谓词表达式，这些表达式可能是：表示列的列值表达式，表示常量的常量表达式，比较表达式，运算表达式等。

举个简单的例子：顺序扫描向单点查询的转换。当顺序扫描的表达式为比较表达式中的等值比较，表达式左右两边为列值表达式与常量表达式，且列值表达式上有所以时，可以将顺序扫描转换成单点查询。但是表达式的类型都是基类指针，C++没有反射，不能查看变量的类型。所以这里可以利用dynamic_cast的动态检查，试着将基类指针向子类指针转换，如果转换成功就能得到指针的类型。



执行计划树分为两种，分别是逻辑执行计划树与物理执行计划树。逻辑执行计划树表示抽象的SQL语句，而物理执行计划树则表示具体的SQL语句。计划树中的每个节点被称为算子，一个逻辑算子对应着一个物理算子。假设一个逻辑算子表示Join操作，与其对应物理算子将表示具体的Join算法，比如哈希Join，嵌套循环，排序合并。

***
## P4：整体介绍

## P4：介绍时间戳系统的实现
每个事务都有两个时间戳，分别是read ts与commit ts，每行数据有不同的版本，每个版本也有一个时间戳。

时间戳作为一个单调递增的序列，开启事务时，将为事务赋予read ts，事务只能看见时间戳小于等于read ts 的数据版本。提交事务时，事务才会被赋予commit ts，由当前事务产生的数据版本，其时间戳将被修改为事务的commit ts。

具体的代码实现中，有一个txn_mgr结构体用来管理事务，它有一个名为last_commit_ts的原子int变量，表示上一个commit的时间戳。begin 事务时，read ts将被赋予last_commit_ts的值，保证了事务最多只能看到上一个事务提交的修改。commit 事务时，commit ts的值等于last_commit_ts的值+1。

只有在事务完全提交后，last_commit_ts的值才会自增。这么做的原因是防止数据竞争，事务未完全提交，但last_commit_ts已经自增，此时begin的事务将会看到一个未完全提交的事务产生的一部分数据版本，这会导致后续的数据错误。
## P4：Watermark介绍
Watermark用来追踪所有事务中，处于活跃状态的的最小的read ts，这将为GC提供支持。

具体的代码实现中，因为不同事务的read ts可能相同，所以我使用了一张unordered_map，以read ts作为key，活跃数量作为value，记录每个读时间戳的活跃数量。此外，还用了一个set以升序的方式，存储unordered_map中的所有read ts。当read ts 的数量从1到0时，需要将该read ts从set中删除。当read ts的数量从0到1时，需要将该read ts添加到set中。那么set的begin指向的read ts，就是处于活跃状态的最小read ts。

## P4：谈谈UndoLog的实现
数据版本的具体实现有两个方向，一是存储完整的数据，这种方式实现简单，但占用了多余的内存。二是只存储增量，也就是数据被修改的部分，这种方式不占用多余的内存，但是应用增量的过程将带来额外的时间开销。

我使用增量实现数据版本。对于每个增量，首先需要存储一个时间戳与一个指针，以表示该增量的创建时间与指向上一个数据版本。增量还需要一个长度等于原数据列数的数组，用bool值表示该列是否被修改。接着还需要一个描述修改数据的tuple，我们需要根据bool数组与原数据的表结构，构造出该tuple的表结构。表结构描述了tuple每个字段的类型与长度，通过表结构可以提取tuple的字段值。

最后，还有一个删除标记位，如果事务被回滚或数据版本被GC清理，将会设置该标记位。

## P4：在MVCC中，事务如何读取数据
原数据和数据版本都有一个时间戳，需要根据事务的read ts，沿着数据的版本链，找到一条当前事务可读的数据版本，这个过程会遇到三种情况：
1. 数据的时间戳小于等于当前事务时间戳，且未被删除，此时可以直接读取
2. 数据正在被一个未提交的事务更新，或者数据版本的ts大于当前事务的时间戳，说明这是一个未来的数据版本，此时需要继续遍历版本链
3. 数据正在被一个未提交的事务修改，且该事务是自己，此时可以直接读取原数据

关于事务正在被修改：我使用了`1 << 62`来表示起始事务ID，如果原数据的时间戳大于等于`1 << 62`，就说明该数据正在被一个事务更新。

最后，数据版本存储的不是完整的数据，而是一个增量，也就是只存储数据被修改的部分。在找第一条可读数据版本的过程中，需要不断地应用这些增量才能得到历史数据。
## P4：UndoLog存储在哪？
每个事务有一个动态数组undo_logs，用来存储自己产生的UndoLog。而UndoLog的指针域实际上有两个字段，指向了产生上一个数据版本的事务，以及该数据版本在undo_logs中的下标。
## P4：VersionLink保存在哪？
txn_mrg有一个version_info成员，其保存了数据库中，所有页以及相应页上page_version_info，page_version_info则根据数据在页上的偏移量保存着每个数据的版本链头，版本链头则指向了数据的第一个版本。
## P4：GC是如何实现的？
数据库中没有事务运行，或者不活跃事务的数量达到一定阈值时，将触发GC。

首先需要向Watermark获取当前数据库中最小的活跃read ts。接着获取数据库中所有的数据表并遍历表中所有数据。然后根据数据的RID获取其版本链，找到第一个最小活跃read ts可读的数据版本，并将之后的数据版本的删除标记位设置为true。

遍历完数据表中的所有数据后，将遍历数据库中的所有已提交事务。事务产生的数据版本将被存储在结构体的undo_logs中，如果undo_logs中的所有数据版本都被删除了，将该事务移除。

但是直接删除事务后会导致悬空指针的问题，因为数据版本的指针域指向了产生上一个数据版本的事务ID以及数据版本在uudo_logs中的下标。事务可能不存在，所以在获取上一个数据版本之前需要先检查事务的有效性，如果事务不存在，则返回nullopt表示一个无效的数据版本。
## P4：行级锁是如何实现的？
名为VersionUndoLink的结构体描述了版本链的链头，它有一个名为in_progress的bool变量，该变量表示数据是否正在被事务修改。

事务修改数据前，需要检查in_progress为false，再保存版本链中的第一个数据版本。然后锁住该数据所在页，进入临界区，再读取版本链的第一个数据版本，保证与之前的数据版本相同且in_progress字段为false，最后更新in_progress字段为true。

总的来说，行级锁实际上是借用了页锁的临界区，保证in_progress的修改操作具有原子性，且在临界区外保存的数据版本正确。从而实现行级锁。
## P4：在MVCC下，如何写入数据？
正常情况下，写入操作需要先调用TableHeap的接口完成数据的插入，并初始化版本链，使其指向一个无效的数据版本。

但存在一些特殊情况：如果数据表存在主键，需要检查唯一性冲突。如果发生了唯一性冲突，需要检查数据的时间戳，判断是否有事务正在修改该数据。如果正在修改该数据的事务是自己，并且该数据被删除，说明自己先执行了删除操作，那么直接更新原数据即可。否则当前终止当前事务。

发生了唯一性冲突，但没有事务正在修改数据时，需要检查这是一条被删除的数据，且原数据对当前事务可见。通过检查后，需要获取行级锁，生成数据版本，更新原数据并维护数据的版本链。

## P4：在MVCC下，如何删除数据？
正常情况下，保证原数据对当前事务可见后，获取行级锁并设置数据的删除标志位即可。

但存在一些特殊情况：如果数据正在被事务修改，并且是自己正在修改，那么需要检查其版本链。如果存在数据版本，则需要基于第一个数据版本生成新的数据版本并替换原数据版本。因为第一个数据版本一定是自己产生的，如果直接生成新的数据版本，将丢失自己之前的修改操作。

如果没有事务正在修改数据，需要检查数据的时间戳，不能删除来自未来的数据。通过检查后，执行正常的删除逻辑即可。
## P4：在MVCC下，如何更新数据？
正常情况下，获取行级锁，生成数据版本并更新版本链，最后更新原数据并释放行级锁即可。

但存在一些特殊情况：如果更新的是主键，需要先保存更新后的所有数据，再将待更新的数据删除，最后插入之前保存的更新后的数据。因为如果直接更新数据，可能导致假的主键冲突，也就是存在两条数据，更新完其中一条后发生了主键冲突，此时更新失败。但两条数据都完成更新后，却没有了主键冲突。

如果更新的不是主键，检查该数据是否正在被事务修改，如果正在被自己修改，且该数据存在版本链，需要基于第一个数据版本生成新的数据版本并替换原数据版本。因为第一个数据版本一定是自己产生的，如果直接生成新的数据版本，将丢失自己之前的修改操作。

如果更新的不是主键，且没有事务正在修改数据，需要检查数据的时间戳，不能更新来自未来的数据。通过检查后，执行正常的更新逻辑即可。

